{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a4fe4e7",
   "metadata": {
    "papermill": {
     "duration": 0.004382,
     "end_time": "2023-04-17T03:11:30.435902",
     "exception": false,
     "start_time": "2023-04-17T03:11:30.431520",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# This notebook uses light-gbm to tackle the Parkinson's Freezing of Gait (FOG) Prediction problem\n",
    "\n",
    "Thanks to JEROENVDD* for pointing out the utility of seglearn and tsflex.\n",
    "\n",
    "tsflex - \"tsflex is a toolkit for flexible time series processing & feature extraction, that is efficient and makes few assumptions about sequence data.\" (https://github.com/predict-idlab/tsflex)\n",
    "\n",
    "seglearn - \"provides an integrated pipeline for segmentation, feature extraction, feature processing, and final estimator. Seglearn provides a flexible approach to multivariate time series and related contextual (meta) data for classification, regression, and forecasting problems\" (https://github.com/dmbee/seglearn)\n",
    "\n",
    "*https://www.kaggle.com/code/jeroenvdd/time-series-tsflex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0113a4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T03:11:30.444563Z",
     "iopub.status.busy": "2023-04-17T03:11:30.444127Z",
     "iopub.status.idle": "2023-04-17T03:11:50.195803Z",
     "shell.execute_reply": "2023-04-17T03:11:50.194571Z"
    },
    "papermill": {
     "duration": 19.759099,
     "end_time": "2023-04-17T03:11:50.198515",
     "exception": false,
     "start_time": "2023-04-17T03:11:30.439416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install tsflex and seglearn - pull in all the whl files that are required for this notebook\n",
    "!pip install tsflex -q --no-index --find-links=file:///kaggle/input/time-series-tools\n",
    "!pip install seglearn -q --no-index --find-links=file:///kaggle/input/time-series-tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5003678",
   "metadata": {
    "papermill": {
     "duration": 0.003311,
     "end_time": "2023-04-17T03:11:50.205721",
     "exception": false,
     "start_time": "2023-04-17T03:11:50.202410",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Datasets\n",
    "\n",
    "Note the two labelled datasets that we have access to, from the competition webpage:\n",
    "\"The tDCS FOG (tdcsfog) dataset, comprising data series collected in the lab, as subjects completed a FOG-provoking protocol.\"\n",
    "\"The DeFOG (defog) dataset, comprising data series collected in the subject's home, as subjects completed a FOG-provoking protocol\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed135901",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-04-17T03:11:50.214065Z",
     "iopub.status.busy": "2023-04-17T03:11:50.213711Z",
     "iopub.status.idle": "2023-04-17T03:11:53.969044Z",
     "shell.execute_reply": "2023-04-17T03:11:53.967993Z"
    },
    "papermill": {
     "duration": 3.762728,
     "end_time": "2023-04-17T03:11:53.971784",
     "exception": false,
     "start_time": "2023-04-17T03:11:50.209056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .time    { background: #40CC40; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tbody td { text-align: left; }\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .sp {  opacity: 0.25;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import commonly used libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pathlib\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn import *\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sklearn\n",
    "\n",
    "# using light-gbm as our model\n",
    "import lightgbm as lgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# import time-series libraries\n",
    "import seglearn\n",
    "from tsflex.features import FeatureCollection, MultipleFeatureDescriptors\n",
    "from tsflex.features.integrations import seglearn_feature_dict_wrapper\n",
    "from sklearn.model_selection import GroupKFold # add k fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38450c79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T03:11:53.982022Z",
     "iopub.status.busy": "2023-04-17T03:11:53.980247Z",
     "iopub.status.idle": "2023-04-17T03:11:54.343071Z",
     "shell.execute_reply": "2023-04-17T03:11:54.342007Z"
    },
    "papermill": {
     "duration": 0.370247,
     "end_time": "2023-04-17T03:11:54.345832",
     "exception": false,
     "start_time": "2023-04-17T03:11:53.975585",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# link to dataset\n",
    "dataset_path = '/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/'\n",
    "\n",
    "# create train and test directories\n",
    "train = glob.glob(dataset_path + 'train/**/**')\n",
    "test = glob.glob(dataset_path + 'test/**/**')\n",
    "\n",
    "# create additional csvs\n",
    "subjects = pd.read_csv(dataset_path + 'subjects.csv')\n",
    "tasks = pd.read_csv(dataset_path + 'tasks.csv')\n",
    "SampleSubmission = pd.read_csv(dataset_path + 'sample_submission.csv')\n",
    "\n",
    "# combine the two datasets mentioned - tdcsfog and defog\n",
    "tdcsfog_metadata=pd.read_csv('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/tdcsfog_metadata.csv')\n",
    "defog_metadata=pd.read_csv('/kaggle/input/tlvmc-parkinsons-freezing-gait-prediction/defog_metadata.csv')\n",
    "\n",
    "tdcsfog_metadata['Module']='tdcsfog'\n",
    "defog_metadata['Module']='defog'\n",
    "\n",
    "metadata=pd.concat([tdcsfog_metadata,defog_metadata])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c203fa7",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-04-17T03:11:54.354633Z",
     "iopub.status.busy": "2023-04-17T03:11:54.354337Z",
     "iopub.status.idle": "2023-04-17T03:11:54.481256Z",
     "shell.execute_reply": "2023-04-17T03:11:54.480387Z"
    },
    "papermill": {
     "duration": 0.1339,
     "end_time": "2023-04-17T03:11:54.483638",
     "exception": false,
     "start_time": "2023-04-17T03:11:54.349738",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# feature engineering\n",
    "\n",
    "# For Tasks: create feature to capture duration of event\n",
    "tasks['Duration'] = tasks['End'] - tasks['Begin']\n",
    "tasks = pd.pivot_table(tasks, values=['Duration'], index=['Id'], columns=['Task'], aggfunc='sum', fill_value=0)\n",
    "tasks.columns = [c[-1] for c in tasks.columns]\n",
    "tasks = tasks.reset_index()\n",
    "\n",
    "# fill data with KMeans\n",
    "tasks['t_kmeans'] = cluster.KMeans(n_clusters=10, random_state=3).fit_predict(tasks[tasks.columns[1:]])\n",
    "\n",
    "# For Subjects: fill data\n",
    "subjects = subjects.fillna(0).groupby('Subject').median()\n",
    "subjects = subjects.reset_index()\n",
    "\n",
    "# fill data with KMeans\n",
    "subjects['s_kmeans'] = cluster.KMeans(n_clusters=10, random_state=3).fit_predict(subjects[subjects.columns[1:]])\n",
    "subjects=subjects.rename(columns={'Visit':'s_Visit','Age':'s_Age','YearsSinceDx':'s_YearsSinceDx','UPDRSIII_On':'s_UPDRSIII_On','UPDRSIII_Off':'s_UPDRSIII_Off','NFOGQ':'s_NFOGQ'})\n",
    "\n",
    "complex_featlist = ['Medication', 'Test', 'Visit', 's_Age', 's_NFOGQ', 's_UPDRSIII_Off', 's_UPDRSIII_On', 's_Visit', 's_YearsSinceDx', 's_kmeans']\n",
    "\n",
    "metadata_complex=metadata.merge(subjects,how='left',on='Subject').copy()\n",
    "metadata_complex['Medication']=metadata_complex['Medication'].factorize()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ed15711",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2023-04-17T03:11:54.493224Z",
     "iopub.status.busy": "2023-04-17T03:11:54.492645Z",
     "iopub.status.idle": "2023-04-17T03:11:54.501302Z",
     "shell.execute_reply": "2023-04-17T03:11:54.500367Z"
    },
    "papermill": {
     "duration": 0.015542,
     "end_time": "2023-04-17T03:11:54.503451",
     "exception": false,
     "start_time": "2023-04-17T03:11:54.487909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using tsflex library for time-series feature extraction\n",
    "# MultipleFeatureDescriptors class from seglearn for defining multiple feature descriptors\n",
    "\n",
    "# define a window of 5k\n",
    "windowSize = [5_000]\n",
    "\n",
    "# create feature descriptors for base features\n",
    "baseFeatures = MultipleFeatureDescriptors(\n",
    "    functions = seglearn_feature_dict_wrapper(seglearn.feature_functions.base_features()),\n",
    "    series_names = ['AccV', 'AccML', 'AccAP'],\n",
    "    windows = windowSize,\n",
    "    strides = windowSize, # even stride\n",
    ")\n",
    "\n",
    "# create feature descriptors for EMG features\n",
    "emgFeatures = seglearn.feature_functions.emg_features()\n",
    "del emgFeatures['simple square integral'] # delete duplicate category\n",
    "\n",
    "emgFeatures = MultipleFeatureDescriptors(\n",
    "    functions = seglearn_feature_dict_wrapper(emgFeatures),\n",
    "    series_names = ['AccV', 'AccML', 'AccAP'],\n",
    "    windows = windowSize,\n",
    "    strides = windowSize, # even stride\n",
    ")\n",
    "\n",
    "fc = FeatureCollection([baseFeatures, emgFeatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "765ce928",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T03:11:54.512058Z",
     "iopub.status.busy": "2023-04-17T03:11:54.511744Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2023-04-17T03:11:54.507142",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dd9d20a62284fd1adb402c792d84279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/970 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def readFunction(f):\n",
    "    try:\n",
    "        # import the csv file as a pandas dataframe\n",
    "        df = pd.read_csv(f, index_col=\"Time\", usecols=['Time', 'AccV', 'AccML', 'AccAP', 'StartHesitation', 'Turn' , 'Walking'])\n",
    "        \n",
    "        # edit features\n",
    "        df['Id'] = f.split('/')[-1].split('.')[0]\n",
    "        df['Module'] = pathlib.Path(f).parts[-2]\n",
    "        df['Time_frac'] = (df.index/df.index.max()).values #currently the index of data is actually \"Time\"\n",
    "        \n",
    "        # merge vecs\n",
    "        df = pd.merge(df, tasks[['Id','t_kmeans']], how='left', on='Id').fillna(-1)\n",
    "        df = pd.merge(df, metadata_complex[['Id','Subject']+['Visit','Test','Medication','s_kmeans']], how='left', on='Id').fillna(-1)\n",
    "        df_feats = fc.calculate(df, return_df=True, include_final_window=True, approve_sparsity=True, window_idx=\"begin\").astype(np.float32)\n",
    "        df = df.merge(df_feats, how=\"left\", left_index=True, right_index=True)\n",
    "        df.fillna(method=\"ffill\", inplace=True)\n",
    "        return df\n",
    "    \n",
    "    except: pass\n",
    "\n",
    "# if not os.path.exists(dataset_path + 'data.pkl'):\n",
    "#     # run read function\n",
    "train = pd.concat([readFunction(f) for f in tqdm(train)]).fillna(0)\n",
    "train = train.reset_index(drop=True)\n",
    "# the file is too big to be saved in a pickle file!\n",
    "#     # Save dataframe to a pickle file\n",
    "#     try:\n",
    "#         with open('/kaggle/working/data.pkl', 'wb') as file:\n",
    "#             pickle.dump(train, file)\n",
    "#         print('saved file to: ' + '/kaggle/working/data.pkl')\n",
    "#     else:\n",
    "#         print(\"couldn't save, likely read-only\")\n",
    "# else:\n",
    "#     # Load dataframe from the pickle file\n",
    "#     with open('/kaggle/working/data.pkl', 'rb') as file:\n",
    "#         train = pickle.load(file)\n",
    "#     print('loaded file from: ' + '/kaggle/working/data.pkl')\n",
    "\n",
    "cols = [c for c in train.columns if c not in ['Id','Subject','Module', 'Time', 'StartHesitation', 'Turn' , 'Walking', 'Valid', 'Task','Event']]\n",
    "pcols = ['StartHesitation', 'Turn' , 'Walking']\n",
    "scols = ['Id', 'StartHesitation', 'Turn' , 'Walking']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6017eb8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339613a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T02:57:04.919087Z",
     "iopub.status.busy": "2023-04-17T02:57:04.918583Z",
     "iopub.status.idle": "2023-04-17T02:57:04.934245Z",
     "shell.execute_reply": "2023-04-17T02:57:04.932604Z",
     "shell.execute_reply.started": "2023-04-17T02:57:04.919038Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# customize for light-gbm \n",
    "class LGBMMultiOutputRegressor(MultiOutputRegressor):\n",
    "    \n",
    "    def fit(self, X, y, eval_set=None, **fit_params):\n",
    "        \n",
    "        # copy base estimator for each output \n",
    "        self.estimators_ = [sklearn.base.clone(self.estimator) for indx in range(0,y.shape[1])]\n",
    "        \n",
    "        # Fit the estimators\n",
    "        for i, estimator in enumerate(self.estimators_):\n",
    "            \n",
    "            if eval_set is not None:\n",
    "                eval_set_i = (eval_set[0], eval_set[1][:, i])\n",
    "                fit_params['eval_set'] = [eval_set_i]\n",
    "            \n",
    "            estimator.fit(X, y[:, i], **fit_params)\n",
    "\n",
    "        return self\n",
    "\n",
    "# patching ap scoring for light-gbm\n",
    "def lgbm_ap(y_true, y_pred):\n",
    "    \n",
    "    score = average_precision_score(y_true, y_pred)\n",
    "    \n",
    "    return 'average_precision', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ffe03b",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2023-04-17T03:01:00.311490Z",
     "iopub.status.busy": "2023-04-17T03:01:00.309135Z",
     "iopub.status.idle": "2023-04-17T03:09:00.360263Z",
     "shell.execute_reply": "2023-04-17T03:09:00.358086Z",
     "shell.execute_reply.started": "2023-04-17T03:01:00.311402Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting up for 5-fold cross validation\n",
    "numFolds = 5\n",
    "kFolds = GroupKFold(numFolds)\n",
    "groups = kFolds.split(train, groups = train.Subject)\n",
    "regs, cvs = [], []\n",
    "\n",
    "for fold, (trainIndex,testIndex) in enumerate(tqdm(groups, total = numFolds)):\n",
    "    trainIndex = pd.Series(trainIndex).sample(n = 200,random_state = 1).values\n",
    "    \n",
    "    # Create a light-gbm regressor\n",
    "    base_regressor = lgb.LGBMRegressor(\n",
    "    max_depth = 8,\n",
    "    learning_rate = 0.2,\n",
    "    n_estimators = 300,\n",
    "    subsample = 0.99,\n",
    "    min_child_weight = 3.12,\n",
    "    colsample_bytree = 0.5\n",
    "    )\n",
    "\n",
    "    # Wrap the base regressor with the MultiOutputRegressor\n",
    "    multioutput_regressor = LGBMMultiOutputRegressor(base_regressor)\n",
    "\n",
    "    # set up data\n",
    "    # train\n",
    "    xTrain = train.loc[trainIndex,cols].to_numpy()\n",
    "    yTrain = train.loc[trainIndex,pcols].to_numpy()\n",
    "    \n",
    "    # test\n",
    "    xTest = train.loc[testIndex,cols].to_numpy()\n",
    "    yTest = train.loc[testIndex,pcols].to_numpy()\n",
    "    \n",
    "    # define early stopping callback\n",
    "    early_stopping = lgb.callback.early_stopping(\n",
    "        stopping_rounds = 25, # number of rounds to wait before stopping if no improvement\n",
    "        verbose = False, # print message when stopping\n",
    "        first_metric_only = True,\n",
    "    )\n",
    "    \n",
    "    # train light-gbm\n",
    "    multioutput_regressor.fit(\n",
    "    xTrain,\n",
    "    yTrain,\n",
    "    eval_set = (xTest,yTest),\n",
    "    eval_metric=lgbm_ap,\n",
    "    early_stopping_rounds=25\n",
    "    )\n",
    "    regs.append(multioutput_regressor)\n",
    "    cv=metrics.average_precision_score(yTest, multioutput_regressor.predict(xTest).clip(0.0,1.0))\n",
    "    cvs.append(cv)\n",
    "print(cvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb4161e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Predict for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0362bfed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T03:09:14.958793Z",
     "iopub.status.busy": "2023-04-17T03:09:14.958282Z",
     "iopub.status.idle": "2023-04-17T03:09:21.146735Z",
     "shell.execute_reply": "2023-04-17T03:09:21.145581Z",
     "shell.execute_reply.started": "2023-04-17T03:09:14.958744Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SampleSubmission['t'] = 0\n",
    "SampleSubmission = []\n",
    "\n",
    "for f in test:\n",
    "    df = pd.read_csv(f)\n",
    "    df.set_index('Time', drop = True, inplace = True)\n",
    "\n",
    "    df['Id'] = f.split('/')[-1].split('.')[0]\n",
    "    df['Time_frac'] = (df.index/df.index.max()).values#currently the index of data is actually \"Time\"\n",
    "    df = pd.merge(df, tasks[['Id','t_kmeans']], how = 'left', on = 'Id').fillna(-1)\n",
    "    df = pd.merge(df, metadata_complex[['Id','Subject'] + ['Visit','Test','Medication','s_kmeans']], how = 'left', on = 'Id').fillna(-1)\n",
    "    df_feats = fc.calculate(df, return_df = True, include_final_window = True, approve_sparsity = True, window_idx = \"begin\")\n",
    "    df = df.merge(df_feats, how = \"left\", left_index = True, right_index = True)\n",
    "    df.fillna(method = \"ffill\", inplace = True)\n",
    "    \n",
    "    res_vals=[]\n",
    "\n",
    "    for i_fold in range(numFolds):\n",
    "        res_val=np.round(regs[i_fold].predict(df[cols]).clip(0.0,1.0),3)\n",
    "        res_vals.append(np.expand_dims(res_val,axis = 2))\n",
    "    res_vals=np.mean(np.concatenate(res_vals,axis = 2),axis = 2)\n",
    "    res = pd.DataFrame(res_vals, columns = pcols)\n",
    "    \n",
    "    df = pd.concat([df,res], axis=1)\n",
    "    df['Id'] = df['Id'].astype(str) + '_' + df.index.astype(str)\n",
    "    SampleSubmission.append(df[scols])\n",
    "    \n",
    "SampleSubmission = pd.concat(SampleSubmission)\n",
    "SampleSubmission = pd.merge(SampleSubmission[['Id']], SampleSubmission, how='left', on='Id').fillna(0.0)\n",
    "SampleSubmission[scols].to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fef84a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-17T03:10:46.721111Z",
     "iopub.status.busy": "2023-04-17T03:10:46.720530Z",
     "iopub.status.idle": "2023-04-17T03:10:46.736317Z",
     "shell.execute_reply": "2023-04-17T03:10:46.734749Z",
     "shell.execute_reply.started": "2023-04-17T03:10:46.721064Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SampleSubmission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-17T03:11:20.994556",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}